{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Design and Develop the Prompt Generation System\n",
    "- Users can input a description of their objective or task and specify a few scenarios along with their expected outputs. \n",
    "- Write or adopt sophisticated algorithms, you generate multiple prompt options based on the provided information. \n",
    "- This automated prompt generation process saves time and provides a diverse <br/>\n",
    "range of alternatives to consider. But add an evaluation metrics that check <br/> \n",
    "whether the generated prompt candidate aligns with the input description.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from dotenv import load_dotenv,find_dotenv\n",
    "sys.path.append(os.path.abspath(os.path.join('../utility')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/babi/miniconda3/envs/tenx_week6/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from rag import create_retriever\n",
    "from langchain_utility import data_loader, create_chain_rag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load OPENAI KEY from .env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load OpenAI API key from .env file\n",
    "load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the dataset and create chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-18 23:17:15,977:logger:data loaded to vector database successfullu\n"
     ]
    }
   ],
   "source": [
    "chunks = data_loader()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create vector database and retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started /home/babi/.cache/weaviate-embedded: process ID 977761\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{\"action\":\"startup\",\"default_vectorizer_module\":\"none\",\"level\":\"info\",\"msg\":\"the default vectorizer modules is set to \\\"none\\\", as a result all new schema classes without an explicit vectorizer setting, will use this vectorizer\",\"time\":\"2024-01-18T23:17:17+03:00\"}\n",
      "{\"action\":\"startup\",\"auto_schema_enabled\":true,\"level\":\"info\",\"msg\":\"auto schema enabled setting is set to \\\"true\\\"\",\"time\":\"2024-01-18T23:17:17+03:00\"}\n",
      "{\"level\":\"info\",\"msg\":\"No resource limits set, weaviate will use all available memory and CPU. To limit resources, set LIMIT_RESOURCES=true\",\"time\":\"2024-01-18T23:17:17+03:00\"}\n",
      "{\"level\":\"warning\",\"msg\":\"Multiple vector spaces are present, GraphQL Explore and REST API list objects endpoint module include params has been disabled as a result.\",\"time\":\"2024-01-18T23:17:18+03:00\"}\n",
      "{\"action\":\"grpc_startup\",\"level\":\"info\",\"msg\":\"grpc server listening at [::]:50060\",\"time\":\"2024-01-18T23:17:18+03:00\"}\n",
      "{\"action\":\"restapi_management\",\"level\":\"info\",\"msg\":\"Serving weaviate at http://127.0.0.1:8079\",\"time\":\"2024-01-18T23:17:18+03:00\"}\n",
      "/home/babi/miniconda3/envs/tenx_week6/lib/python3.12/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.embeddings.openai.OpenAIEmbeddings` was deprecated in langchain-community 0.1.0 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAIEmbeddings`.\n",
      "  warn_deprecated(\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_0a43cce8a9f54813a3ad4f3d498d6434_NISdUtmHet4a in 1.883988ms\",\"time\":\"2024-01-18T23:17:19+03:00\"}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-01-18T23:17:19+03:00\",\"took\":125907}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_27909b9fdb7a488d8ff0a8d01137ed9a_IFose2oTztrN in 1.017739ms\",\"time\":\"2024-01-18T23:17:19+03:00\"}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-01-18T23:17:19+03:00\",\"took\":126746}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_133fb572c0784fe9b7544b27354d2e3a_4kCtu55fH4aJ in 2.669439ms\",\"time\":\"2024-01-18T23:17:19+03:00\"}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-01-18T23:17:19+03:00\",\"took\":124694}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_1f41348bf9cd4390b44def9261cf2bc8_XKxlbIuwtk65 in 3.579508ms\",\"time\":\"2024-01-18T23:17:19+03:00\"}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_a136104104f14d6ab12f98e6d39d11ca_1sAiUUcGKQew in 1.956972ms\",\"time\":\"2024-01-18T23:17:19+03:00\"}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-01-18T23:17:19+03:00\",\"took\":126951}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_28f3bb7c9b5247ca9a2432f01796c027_a8dhg0N9Rrpj in 4.376946ms\",\"time\":\"2024-01-18T23:17:19+03:00\"}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-01-18T23:17:19+03:00\",\"took\":216078}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-01-18T23:17:19+03:00\",\"took\":991175}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_3773278af3bf44c6974be51681bd1435_rGM6mbuHbah4 in 5.475539ms\",\"time\":\"2024-01-18T23:17:19+03:00\"}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_50957979f294425586dea6a1fc969dbd_jjAnWw4sTNE0 in 5.751852ms\",\"time\":\"2024-01-18T23:17:19+03:00\"}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-01-18T23:17:19+03:00\",\"took\":204292}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-01-18T23:17:19+03:00\",\"took\":182552}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_66b4400d9994425ca7e1eb543bcb3041_MpzRapwC4z4d in 47.372543ms\",\"time\":\"2024-01-18T23:17:19+03:00\"}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-01-18T23:17:19+03:00\",\"took\":117145}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_ac8d1707c3e14e42b2f3bb65ab8540f3_fgTj1UOo3Lyl in 44.979106ms\",\"time\":\"2024-01-18T23:17:19+03:00\"}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-01-18T23:17:19+03:00\",\"took\":131008}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_83bb50859fcf4f7dbda201a126101d39_GjLVFWvBwn0m in 45.155427ms\",\"time\":\"2024-01-18T23:17:19+03:00\"}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-01-18T23:17:19+03:00\",\"took\":131062}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_6d770baf40a84c93824e03a28cb7f5dc_0xSq7UdVBXTv in 50.466667ms\",\"time\":\"2024-01-18T23:17:19+03:00\"}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_1ce42fd9e730438cb975281984762d81_wiq6iQ2n0QO1 in 51.783657ms\",\"time\":\"2024-01-18T23:17:19+03:00\"}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_5ce0983842194bea9e99d259f65cc4a8_lE0K6y1kCAbu in 32.139294ms\",\"time\":\"2024-01-18T23:17:19+03:00\"}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-01-18T23:17:19+03:00\",\"took\":192745}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-01-18T23:17:19+03:00\",\"took\":1320242}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_a0795a009713456ca35fb1fb03d0eb02_9pzvFtVa9APs in 49.73334ms\",\"time\":\"2024-01-18T23:17:19+03:00\"}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_bd28b646c29f4dfaa4406f82e93d590c_bIenm7yfBFIv in 32.77847ms\",\"time\":\"2024-01-18T23:17:19+03:00\"}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-01-18T23:17:19+03:00\",\"took\":885013}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-01-18T23:17:19+03:00\",\"took\":193899}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_c7caa635303c448e95b5f71ba08b2956_aFk0U0CKJvlt in 50.96109ms\",\"time\":\"2024-01-18T23:17:19+03:00\"}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-01-18T23:17:19+03:00\",\"took\":133663}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_a123bfc441ec42dc975cdacf35cc9168_H2WVKppAR39N in 52.362916ms\",\"time\":\"2024-01-18T23:17:19+03:00\"}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-01-18T23:17:19+03:00\",\"took\":978768}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_3dae534c1d4b4e1d837fe6bf85642817_giWKfwQSgDlY in 48.794329ms\",\"time\":\"2024-01-18T23:17:19+03:00\"}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-01-18T23:17:19+03:00\",\"took\":846460}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_3befa79eada749aea183be1ebacf70bd_WMM4etojJlF5 in 49.430917ms\",\"time\":\"2024-01-18T23:17:19+03:00\"}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_7ab4e39a2959450f9d25c4f094c1ed65_RbKsTje6S11Q in 51.431259ms\",\"time\":\"2024-01-18T23:17:19+03:00\"}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_baa7b447464f4fdbb3aca5187cb22e74_dtviWxFZoxRT in 34.345186ms\",\"time\":\"2024-01-18T23:17:19+03:00\"}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-01-18T23:17:19+03:00\",\"took\":182601}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_7b7f5764552a48a7af2fcbbc8a09143e_3COgv4JNXIVP in 34.207169ms\",\"time\":\"2024-01-18T23:17:19+03:00\"}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_653cbe3e6689480293e4a8215b930959_nlo2bDOgVacv in 48.289333ms\",\"time\":\"2024-01-18T23:17:19+03:00\"}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-01-18T23:17:19+03:00\",\"took\":876494}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-01-18T23:17:19+03:00\",\"took\":877229}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-01-18T23:17:19+03:00\",\"took\":999645}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-01-18T23:17:19+03:00\",\"took\":861920}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-01-18T23:17:19+03:00\",\"took\":2880670}\n",
      "{\"level\":\"info\",\"msg\":\"Created shard langchain_4d0a9a62ea9d447ab137ed1062a18e7f_qcocbx6c3vWD in 1.012742ms\",\"time\":\"2024-01-18T23:17:19+03:00\"}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":1000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-01-18T23:17:19+03:00\",\"took\":158198}\n",
      "/home/babi/miniconda3/envs/tenx_week6/lib/python3.12/site-packages/langchain_community/embeddings/openai.py:500: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.5/migration/\n",
      "  response = response.dict()\n",
      "/home/babi/miniconda3/envs/tenx_week6/lib/python3.12/site-packages/pydantic/main.py:979: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.5/migration/\n",
      "  warnings.warn('The `dict` method is deprecated; use `model_dump` instead.', DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "retriever = create_retriever(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['Weaviate', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.weaviate.Weaviate object at 0x7f35548972c0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the path to your .txt file\n",
    "file_path = '../prompts/prompt-generation-prompt.txt'\n",
    "\n",
    "# Open the file in read mode\n",
    "with open(file_path, 'r') as file:\n",
    "    # Read the contents of the file\n",
    "    file_contents = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-18 23:17:52,516:logger:data loaded to vector database successfully\n"
     ]
    }
   ],
   "source": [
    "rag_chain = create_chain_rag(retriever, file_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  context: VectorStoreRetriever(tags=['Weaviate', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.weaviate.Weaviate object at 0x7f35548972c0>),\n",
       "  question: RunnablePassthrough()\n",
       "}\n",
       "| ChatPromptTemplate(input_variables=['context', 'question'], messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], template=\"You are a prompt generator which generate a list of prompts paired with their ground truth for the user\\nquestion a.  Use the following pieces of retrieved context to answer the question. \\nIf you don't know the answer, just say that you don't know. \\nUse two sentences maximum and keep the answer concise. return a list of 5 prompts with their ground truth. \\nreturn in json format\\nQuestion: {question} \\nContext: {context} \\nAnswer:\"))])\n",
       "| ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x7f3527e2a300>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x7f355464df40>, temperature=0.0, openai_api_key='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', openai_proxy='')\n",
       "| StrOutputParser()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/babi/miniconda3/envs/tenx_week6/lib/python3.12/site-packages/langchain_community/embeddings/openai.py:500: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.5/migration/\n",
      "  response = response.dict()\n",
      "/home/babi/miniconda3/envs/tenx_week6/lib/python3.12/site-packages/pydantic/main.py:979: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.5/migration/\n",
      "  warnings.warn('The `dict` method is deprecated; use `model_dump` instead.', DeprecationWarning)\n",
      "/home/babi/miniconda3/envs/tenx_week6/lib/python3.12/site-packages/langchain_community/chat_models/openai.py:458: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.5/migration/\n",
      "  response = response.dict()\n",
      "/home/babi/miniconda3/envs/tenx_week6/lib/python3.12/site-packages/pydantic/main.py:979: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.5/migration/\n",
      "  warnings.warn('The `dict` method is deprecated; use `model_dump` instead.', DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "generated_prompts = rag_chain.invoke(\"questions about the challenge documnet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[\\n  {\\n    \"prompt\": \"When did OpenAI showcase the capabilities of reinforcement learning algorithms through its \\'OpenAI Five\\' project?\",\\n    \"ground_truth\": \"OpenAI showcased the capabilities of these reinforcement learning algorithms through its ‘OpenAI Five’ project in 2018.\"\\n  },\\n  {\\n    \"prompt\": \"Who founded OpenAI?\",\\n    \"ground_truth\": \"OpenAI was initially founded in 2015 by Sam Altman, Elon Musk, Ilya Sutskever and Greg Brockman.\"\\n  },\\n  {\\n    \"prompt\": \"What is the goal of OpenAI?\",\\n    \"ground_truth\": \"The stated goal of OpenAI is to \\'advance digital intelligence in the way that is most likely to benefit humanity as a whole.\\'\"\\n  },\\n  {\\n    \"prompt\": \"What did OpenAI release in 2016?\",\\n    \"ground_truth\": \"OpenAI released \\'OpenAI Gym\\' in 2016, a toolkit for developing and comparing reinforcement learning algorithms.\"\\n  },\\n  {\\n    \"prompt\": \"What did OpenAI achieve in the early years?\",\\n    \"ground_truth\": \"OpenAI made significant progress in research in deep learning and reinforcement learning in the early years.\"\\n  }\\n]'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_prompts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'prompt': \"When did OpenAI showcase the capabilities of reinforcement learning algorithms through its 'OpenAI Five' project?\",\n",
       "  'ground_truth': 'OpenAI showcased the capabilities of these reinforcement learning algorithms through its ‘OpenAI Five’ project in 2018.'},\n",
       " {'prompt': 'Who founded OpenAI?',\n",
       "  'ground_truth': 'OpenAI was initially founded in 2015 by Sam Altman, Elon Musk, Ilya Sutskever and Greg Brockman.'},\n",
       " {'prompt': 'What is the goal of OpenAI?',\n",
       "  'ground_truth': \"The stated goal of OpenAI is to 'advance digital intelligence in the way that is most likely to benefit humanity as a whole.'\"},\n",
       " {'prompt': 'What did OpenAI release in 2016?',\n",
       "  'ground_truth': \"OpenAI released 'OpenAI Gym' in 2016, a toolkit for developing and comparing reinforcement learning algorithms.\"},\n",
       " {'prompt': 'What did OpenAI achieve in the early years?',\n",
       "  'ground_truth': 'OpenAI made significant progress in research in deep learning and reinforcement learning in the early years.'}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{\"level\":\"info\",\"msg\":\"Created shard langchain_249710fa43a04b028c6088aa0bcb5637_5JcTAjbnLlS2 in 2.811321ms\",\"time\":\"2024-01-18T23:23:19+03:00\"}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":1000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-01-18T23:23:19+03:00\",\"took\":463004}\n",
      "{\"level\":\"info\",\"msg\":\"Created shard langchain_4b51e0a56e34429294183d836886bbf5_chZtzv3vlG0X in 1.083476ms\",\"time\":\"2024-01-18T23:25:50+03:00\"}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":1000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-01-18T23:25:50+03:00\",\"took\":164332}\n",
      "{\"level\":\"info\",\"msg\":\"Created shard langchain_dfad81fac8e04bf9a5dc95399e7c1293_mUFMm1hng3t7 in 969.508µs\",\"time\":\"2024-01-18T23:31:55+03:00\"}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":1000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-01-18T23:31:55+03:00\",\"took\":99800}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "prompt_data = json.loads(generated_prompts)\n",
    "prompt_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tenx_week6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
